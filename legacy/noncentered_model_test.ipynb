{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ebf90a-0a96-4e38-9391-d54b2f3d7ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssms\n",
    "def sim_wrap(theta = torch.zeros(0), model = 'ddm', n_samples = 1, output_format = 'torch'):\n",
    "    theta = theta.squeeze()\n",
    "    \n",
    "    if theta.dim() == 3:\n",
    "        out_list = []\n",
    "        out_processed_list = []\n",
    "        \n",
    "        for i in range(theta.shape[0]):\n",
    "            theta_tmp = theta[i, ...].numpy().astype(np.float32)\n",
    "    \n",
    "            out_tmp = ssms.basic_simulators.simulator(theta = theta_tmp,\n",
    "                                                      model = model,\n",
    "                                                      n_samples = n_samples,\n",
    "                                                      delta_t = 0.001,\n",
    "                                                      max_t = 20.0,\n",
    "                                                      no_noise = False,\n",
    "                                                      bin_dim = None,\n",
    "                                                      bin_pointwise = False)\n",
    "        \n",
    "            out_processed_list.append(np.concatenate([out_tmp['rts'].astype(np.float32), \n",
    "                                                      out_tmp['choices'].astype(np.float32)], axis = -1))\n",
    "            \n",
    "        return torch.tensor(np.stack(out_processed_list))\n",
    "            \n",
    "    elif (theta.dim() == 2) or (theta.dim() == 1):\n",
    "        theta_tmp = theta.numpy().astype(np.float32)\n",
    "        out_tmp = ssms.basic_simulators.simulator(theta = theta_tmp,\n",
    "                                                  model = model,\n",
    "                                                  n_samples = n_samples,\n",
    "                                                  delta_t = 0.001,\n",
    "                                                  max_t = 20.0,\n",
    "                                                  no_noise = False,\n",
    "                                                  bin_dim = None,\n",
    "                                                  bin_pointwise = False)\n",
    "        return torch.tensor(np.concatenate([out_tmp['rts'].astype(np.float32), \n",
    "                                                out_tmp['choices'].astype(np.float32)], axis = -1))\n",
    "    else:\n",
    "        raise NotImplementedError(\"theta should be of dimensionality 2 or 3 after squeezing\")\n",
    "        \n",
    "            \n",
    "def model_maker(model = 'ddm'):\n",
    "    model_config = ssms.config.model_config[model]\n",
    "    def ssm_model(num_trials, data, network):\n",
    "        param_list = []\n",
    "        for param in model_config['params']:\n",
    "            idx = model_config['params'].index(param)\n",
    "            param_list.append(pyro.sample(param, dist.Uniform(model_config['param_bounds'][0][idx],\n",
    "                                                              model_config['param_bounds'][1][idx])))\n",
    "\n",
    "        with pyro.plate(\"data\", num_trials) as data_plate:\n",
    "            return pyro.sample(\"obs\", \n",
    "                               SSMDist(torch.stack(param_list, dim = -1), \n",
    "                                       num_trials, \n",
    "                                       network, \n",
    "                                       model), \n",
    "                               obs = data)\n",
    "    return ssm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a5b929-e939-4ab1-afa7-bd1534e69ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "# Parameter recovery\n",
    "n_samples = 1000 # total number of samples --> n_samples_go + n_samples_nogo = 2 * n_samples_go\n",
    "n_parameter_samples = 200 # number of parameter vectors to samples and run the recovery over\n",
    "std_denominator = 6 # a scaler for the standard deviation applied when sampling parameters in the allowed range\n",
    "\n",
    "parameter_samples_dict = {}\n",
    "\n",
    "for param in model_config[\"params\"]:\n",
    "    myclip_a = model_config[\"param_bounds\"][0][model_config[\"params\"].index(param)]\n",
    "    myclip_b = model_config[\"param_bounds\"][1][model_config[\"params\"].index(param)]\n",
    "    \n",
    "    my_mean = myclip_a + (1/2) * (myclip_b - myclip_a)\n",
    "    my_std = (myclip_b - myclip_a) / std_denominator\n",
    "    \n",
    "    a, b = (myclip_a - my_mean) / my_std, (myclip_b - my_mean) / my_std\n",
    "\n",
    "    parameter_samples_dict[param] = truncnorm.rvs(a, \n",
    "                                                  b, \n",
    "                                                  loc = my_mean, \n",
    "                                                  scale = my_std, size = n_parameter_samples)\n",
    "\n",
    "    plt.hist(parameter_samples_dict[param], alpha = 0.5, histtype = 'step', label = param)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634c53ff-d5f7-48a0-a87c-da97db1cf0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = sim_wrap(theta = torch.tensor(np.array([parameter_samples_dict[key_][0] for key_ in parameter_samples_dict.keys()], \n",
    "                                             dtype = np.float32)),\n",
    "               model = model,\n",
    "               n_samples = n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80984a97-1a4c-4fc9-b117-61ff98ad4ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchical_noncentered_ddm_model(num_subjects, num_trials, data):\n",
    "    v_mu_mu = npy.sample(\"v_mu_mu\", dist.Uniform(-3, 3))\n",
    "    v_mu_std = npy.sample(\"v_mu_std\", dist.HalfNormal(1.))\n",
    "    \n",
    "    a_mu_mu = npy.sample(\"a_mu_mu\", dist.Uniform(0.3, 2.5))\n",
    "    a_mu_std = npy.sample(\"a_mu_std\", dist.HalfNormal(1.))\n",
    "    \n",
    "    z_mu_mu = npy.sample(\"z_mu_mu\", dist.Uniform(0.1, 0.9))\n",
    "    z_mu_std = npy.sample(\"z_mu_std\", dist.HalfNormal(1.))\n",
    "    \n",
    "    t_mu_mu = npy.sample(\"t_mu_mu\", dist.Uniform(0.0, 2.0))\n",
    "    t_mu_std = npy.sample(\"t_mu_std\", dist.HalfNormal(1.))\n",
    "    \n",
    "    with npy.plate(\"subjects\", num_subjects) as subjects_plate:\n",
    "        v_subj_z = npy.sample(\"v_subj_z\", \n",
    "                               dist.Normal(0.0, 1.0))\n",
    "        a_subj_z = npy.sample(\"a_subj_z\", \n",
    "                               dist.Normal(0.0, 1.0))\n",
    "        z_subj_z = npy.sample(\"z_subj_z\", \n",
    "                               dist.Normal(0.0, 1.0))\n",
    "        t_subj_z = npy.sample(\"t_subj_z\", \n",
    "                               dist.Normal(0.0, 1.0))\n",
    "        \n",
    "        v_subj = npy.deterministic(\"v_subj\", v_mu_mu + (v_subj_z * v_mu_std))\n",
    "        a_subj = npy.deterministic(\"a_subj\", a_mu_mu + (a_subj_z * a_mu_std))\n",
    "        z_subj = npy.deterministic(\"z_subj\", z_mu_mu + (z_subj_z * z_mu_std))\n",
    "        t_subj = npy.deterministic(\"t_subj\", t_mu_mu + (t_subj_z * t_mu_std))\n",
    "\n",
    "        with npy.plate(\"data\", num_trials) as data_plate:\n",
    "            return npy.sample(\"obs\", \n",
    "                               MyDDMh(v_subj, a_subj, z_subj, t_subj), \n",
    "                               obs = data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lanfactory",
   "language": "python",
   "name": "lanfactory"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
